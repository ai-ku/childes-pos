\begin{enumerate}
\item We need to clarify the tag set that is used during the
  experiments. May be it is better to give the whole mapping as an
  Appendix section.
\item Data statistics (it is common to all experiments)
\end{enumerate}
\section{Experiment 1: corpus analysis}
In this section we replicate the corpus analyses of \cite{20674613}
and \cite{Mintz200391}.  

\subsection{Input Corpora}

In order to be consistent with \cite{20674613} and \cite{Mintz200391},
we use the same six corpora of child-directed speech from the CHILDES
corpus \citep*{macwhinney2000childes}: Anne and Aran
\citep*{theakston2001role}, Eve \citep*{JCL:1765112}, Naomi
\citep*{sachs1983talking}, Nina \citep*{suppes1974semantics}, Peter
\citep*{Bloom1974380, bloom1975structure}.  Following
\cite{Mintz200391} we only analyze the adult utterances in sessions
where the target child is 2.6 years old or younger.

\subsubsection{Preprocessing}

The grammatical category of words in CHILDES are extracted by first
applying the MOR parser \citep*{macwhinney2000childes} and then using
the POST disambiguator \citep*{sagae2004automatic}.  The accuracy of
CHILDES grammatical categories is approximately 95\%
\citep*{parisse2000automatic} and it is encoded in the MOR line of the
CHILDES corpus.

We apply the following pre-processing steps \citep*{20674613} initial
to our analyses:
\begin{itemize}
\item All punctuation, pause, trailing off and interruption marks are
  treated as utterance boundary marks.
\item Repetitions of a word are kept in the text and their grammatical
  categories are automatically set to the grammatical category of the
  original word.
\item Words that are grammatically necessary but not spoken are
  deleted (grammatical omissions).
\item {\bf Short usages ??}
\end{itemize}

\subsection{Method}
\subsection{Results}

\section{Experiment 2: computational modeling of substitutes}

% Why do we choose feedforward connectionist model?
\cite{20674613} compare the effect of distributional cues from various
type of frames on the learning grammatical category problem by using a
feed-forward connectionist model.  We adopt their framework to compare
the paradigmatic representation (substitute words) with the
syntagmatic representation (flexible frames).
% What are the input and output layer
% What does the connectionist model do? Briefly explain without giving
% too much mathematical details
% Two aspects:  
% description of learning process
% how to represent distributional

A prototypical connectionist model consists of input, hidden and
output layers.  Input and output layers are connected to each other
through the hidden layer.  The behavior of the output units are
determined by the activity of the hidden layers which is triggered by
the input layer.

\subsection{Method}

We train two connectionist models to compare flexible frames ($aX+Xb$)
to the substitute words ($a*b$).

\subsection{Architecture}
% How do they represent the frame information?
For each model we represent the input in the following way,

\begin{itemize}
%#\item $aXb$: Each input unit represents a distinct frame thus only one
% unit is activated (i.e. set to 1) for each target word.
\item {\bf$aX+Xb$ model:} The first and second half of the input units
  correspond to the preceding bigram ($a$) and the succeeding bigram
  ($b$), respectively.  Thus two input units are activated for each
  target word.
\item {\bf $a*b$ model:} Each input unit represents a distinct
  substitute and input units that correspond to the substitutes are set
  to the number of their occurrences in the target word substitutes.
\end{itemize}

% Give an example sentence to show how we represent each frame
Each output unit represents a distinct grammatical category therefore
the models are expected to produce only one active (non-zero) output
unit for each target word.  If there are more than one active units
present in the output layer we assign the largest one as the
grammatical category of the target word.

Both models have 10 output units due to the standard labeling
\citep*{Mintz200391}.

Number of hidden units is set to 200 and initialized randomly for each
model. {\bf backprobagation, learning rate, sigmoid...}


\input{framevssub}

\section{Experiment 2}
Number of subsitutes.  We need to show 16 is better than 1 but 16+ is same
\subsection{Input Corpora}
\subsection{Method}
\subsection{Results}

\section{Experiment 3}
N-gram order 2,3

\section{Experiment 4}
What happens when we change the data size?\\
What happens when we change the vocabulary threshold?\\

\subsection{Input Corpora}
\subsection{Method}
\subsection{Results}

\section{Experiment 5}
Left/rigth context substitute
\subsection{Input Corpora}
\subsection{Method}
\subsection{Results}

\section{Experiment 6}
Other languages that we have in CHILDES

\section{Experiment 7}
What happens if some of the words are given (semi-supervised setting)

\subsection{Input Corpora}
\subsection{Method}
\subsection{Results}



